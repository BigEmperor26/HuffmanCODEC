\section{Performance and benchmarking}
Here we discuss the perfomance evaluation of our algorithm.
We start from a evaluation of some other implementations of Huffman algorithm and then focus on the analysis of our own implementation. 

We include in this section some graphs and statistics but all detailed results are included in the appendix at the end this report.
\subsection{setup}
All data is resulting average of 3 runs to minimize the effect random variance in between runs.
We tested everything on HPC2 cluster of University of Trento.
We also used a single node, using the \verb|--map-by | command to map the correct number of cores to each MPI process.
Each time we submitted as a job to the cluster individually, waiting for the previuos to finish. This is to prevent hiccups due to multiple instances of the program trying to access the same data, which we noticed greatly affect I/O times.

The correctness of our algorithm was easily verified by encoding and then decoding a file, then comparing the decoded result to the original with the \verb|diff| command.
\subsection{datasets}
The dataset was pragmatically generated using a C program , creating text files with characters that follow the frequency of letters in English language. Although for this benchmark are only using the 26 letters of the English alphabet, our algorithm reads bytes of data and can therefore work con any type of file.

In particular we chose to analyze these file sizes 1 MiB, 5 MiB, 10 MiB , 50 MiB, 100 MiB, 500 MiB, 1 GiB, 5 GiB, 10 GiB. This should be enough range to understand different algorithms scale with increasing file sizes.

Secondly, because our algorithm also works with many files at once, we used Linux kernel as benchmark for that scenario. As the time of writing, it is about 1.3 GiB of total size, with about  $\sim$ 84.000 files, which on average are each 16MiB in size.

Considering the dataset sizes and testing we have done, we estimate to have read or wrote about $\sim$ 6 TiB of data for our whole benchmark analysis.
\subsection{Other works}

\subsection{Multithreading evaluation}
In this section we evaluate our algorithm on single files, using multithreading and testing our parallelization perfomances with increasing number of threads available.

We can say that with small files, less than a few MiBs, the algorithm is actually slower with more threads. 
This is likely because the data is not large enough to offset the cost of creating multiple threads. Considering the cost parallel processing, we highly suggest not doing parallelization for small files.

However when the data is large enough our multithreaded approach scales up.

With the largest file (10 GiB) our algorithm has an efficiency of 93\% when tested with 4 threads. This number steadily decreases with the number of threads and we hit 32\% with 24 threads.

It has to be noted that we are heavily limited by the I/O. As we are unable to parallelize the I/O, we are heavily limited by that. Especially writing to disk taskes a considerable amount of time.

As a proof of this, if we consider only the processing section of our algorithm, and ignore the time required by the \verb|fflush()| operation before a \verb|fclose()|, we see significantly better times. Although we start from similar efficiency at low threading, we achieve a 54\% efficiency with 24 threads.

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{"../imgs/Flush vs non Flush"}
	\caption{Encoding times with and without the flush()}
	\label{fig:flush-vs-non-flush}
\end{figure}

If we consider only CPU time, which doesn't count the time spent waiting in I/O, we get incredibile results.
 
We also noticed worse times in decoding than encoding. This is probably due to the fact that we are reading fixed chunks of 4096 bytes in encoding, but when we decode, we read the same chunks which is now of a different size than 4096 bytes. 

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{"../imgs/Encoding vs Decoding"}
	\caption{Encoding vs Decoding times}
	\label{fig:encoding-vs-decoding}
\end{figure}

As cited in the previous section, we also tested a version with lock based synchronization instead of barrier. Although theoretically we should get better results, in practice we almost equal results across the board, with only the largest file having some significant difference. This difference is greater in decoding than in encoding.
\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{"../imgs/Barrier vs Locks encoding"}
	\caption{Barrier vs Lock based synchronization perfomance}
	\label{fig:barrier-vs-locks-encoding}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{"../imgs/Encoding Barrier times"}
	\caption{Encoding times}
	\label{fig:encoding-barrier-times}
\end{figure}

\subsection{Multiprocesssing}
We tested on Linux kernel as benchmark the parallelization perfomances of our algorithm. Theoretically our algoritm should scale very well with increasing number of processes and files, because once the main process sends the list of files to encode to each process there is no further communication between different processes. However we find that real world results are different. 
While we don't expect much perfomances by increasing the number of threads, because the files are on average very small, we should get better results by using many processes.
With increasing number of processes, our algorithm does not scale at all. We believe the main limitation of our algorithm is the I/O of the cluster we tested on. When tested on a local machine \footnote{MacBook A2442} with one thread and 1,2,4 processes, we find that our algorithm does indeed scale with the number of processes. 
\subsection{Memory, storage and other considerations}
Our memory requirements don't scale upwards with the size of the files we need to encode, because at any given time, the most we only store is the size of two buffers, each is a \verb|unsigned char buffer[num_threads][4096]|. These buffers are emptied at each I/O cycle, therefore leading to a high memory efficiency. Only when processing multiple files our memory requirements scale up with the number of files, as each process needs to store information about the files is assigned to process.

We also find that we achieve on average 48\% compression rate of our synthetic data. Instead on Linux kernel, because contains more varied data which consists of mostly code, we achieve a lower 62\% compression rate. Testing on other already compressed data as \verb|.zip| or \verb|AV1| resulted in a compression rate of 100\%.